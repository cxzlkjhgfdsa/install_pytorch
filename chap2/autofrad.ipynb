{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 딥러닝을 가능케한 autograd",
   "id": "adfb4da5a92462d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T00:47:15.651296Z",
     "start_time": "2025-05-17T00:47:14.830529Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "e0561c42db4e443a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T00:47:37.232059Z",
     "start_time": "2025-05-17T00:47:37.227406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "print(x)\n"
   ],
   "id": "d3853d4e08212c94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T00:51:07.659933Z",
     "start_time": "2025-05-17T00:51:07.656527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.])\n",
    "print(x)\n",
    "print(x.requires_grad)\n",
    "\n",
    "x.requires_grad = True\n",
    "print(x)\n",
    "print(x.requires_grad)"
   ],
   "id": "13249798f463dda9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "False\n",
      "tensor([1.], requires_grad=True)\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T00:53:35.998832Z",
     "start_time": "2025-05-17T00:53:35.994515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([2.,], requires_grad=True)\n",
    "y = x**2\n",
    "print(y) # PowBackward0 가 붙어 있다\n",
    "\n",
    "print(x.grad)\n",
    "y.backward()\n",
    "print(x.grad) # y = x**2 를 미분한 2x 의 x 값에 1을 대입한 gradient 값"
   ],
   "id": "af0b9d84b15f926e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.], grad_fn=<PowBackward0>)\n",
      "None\n",
      "tensor([4.])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T01:06:27.425109Z",
     "start_time": "2025-05-17T01:06:27.421393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.,], requires_grad=True)\n",
    "y = x**2\n",
    "print(y)  # grad_fn -> x ( requires_grad 가 True 인 ) 에 대해서 어떤 연산을 했는지 표현\n",
    "          # 가장 마지막 연산만 나타냄 ( 실제로는 모든 연산이 들어가있음 )\n",
    "          # 현재는 제곱 연산을 했으니까 Power 가 들어가있음\n",
    "\n",
    "y.retain_grad()\n",
    "\n",
    "z = 3*y\n",
    "print(z) # 여기서느 grad_fn 이 Multiplication 인걸 확인 가능\n",
    "\n",
    "z.backward()\n",
    "print(x.grad) # chain rule 로 알아냄\n",
    "print(y.grad) # error 발생. leaf-Tensor ( requeires_grad 가 Ture 인 Tensor  ) 가 아니라 error 가 발생한다고 나옴\n",
    "              # y.retain_grad() 를 사용하면 y.grad 가능\n",
    "\n",
    "\n"
   ],
   "id": "c06a03570836d1a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], grad_fn=<PowBackward0>)\n",
      "tensor([3.], grad_fn=<MulBackward0>)\n",
      "tensor([6.])\n",
      "tensor([3.])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T08:20:09.600052Z",
     "start_time": "2025-05-17T08:20:09.596726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.,], requires_grad=True)\n",
    "y = x**2\n",
    "z = 3*y\n",
    "\n",
    "y.backward() # 중간 거부터 미분 가능 , 꼭 뿌리부터 해야되는거 아님\n",
    "print(x.grad)"
   ],
   "id": "64f918c1b8919f75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T08:22:32.081946Z",
     "start_time": "2025-05-17T08:22:32.077878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.,], requires_grad=True)\n",
    "a = x**2\n",
    "b = a+1\n",
    "print(b) # AddBackward0 가 붙어있다\n",
    "c = b**2\n",
    "c.backward()\n",
    "print(x.grad)"
   ],
   "id": "6577f406e87d6a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], grad_fn=<AddBackward0>)\n",
      "tensor([8.])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T08:35:56.449181Z",
     "start_time": "2025-05-17T08:35:56.444863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.,], requires_grad=True)\n",
    "y = torch.tensor([1.,], requires_grad=True)\n",
    "z = 2*x**2 + y**2\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "\n"
   ],
   "id": "594630df569fee7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.])\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T08:36:45.050577Z",
     "start_time": "2025-05-17T08:36:45.046253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.,2.,3.], requires_grad=True)\n",
    "y=torch.sum(x**2) # x1**2 + x2**2 + x3**2\n",
    "y.backward()\n",
    "\n",
    "print(y)\n",
    "print(x.grad)"
   ],
   "id": "1d784f4da3b03456",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<SumBackward0>)\n",
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T08:43:31.980737Z",
     "start_time": "2025-05-17T08:43:31.977532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "x.requires_grad = False #trasfer learning 할 때 사용\n",
    "y = x**2\n",
    "print(y)\n",
    "#y.backward() # error"
   ],
   "id": "ad4affdbaa6b84c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T08:44:49.781648Z",
     "start_time": "2025-05-17T08:44:49.777853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([2.,], requires_grad=True)\n",
    "x2 = x.detach() # detach 는 requires_grad = False 인 새로운 텐서를 만드는 것\n",
    "print(x)\n",
    "print(x2)\n",
    "y=x**2\n",
    "print(y)\n",
    "y2=x2**2\n",
    "print(y2)"
   ],
   "id": "404c1bad7be65bd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], requires_grad=True)\n",
      "tensor([2.])\n",
      "tensor([4.], grad_fn=<PowBackward0>)\n",
      "tensor([4.])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**detach 사용 용도**",
   "id": "4ca973fa8af1f8c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T08:47:27.147804Z",
     "start_time": "2025-05-17T08:47:27.143299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.,], requires_grad=True)\n",
    "y = x**2\n",
    "z = y.detach() # x로 만든 것을 상수로 사용 하고 싶을 때 사용\n",
    "               # 중간에 y.requires_grad = False 같은걸 못하기 떄문에 사용\n",
    "w=y+z # x**2+1 과 같다\n",
    "w.backward()\n",
    "print(x.grad)"
   ],
   "id": "e6f79e0985d1794a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**많이 사용되는 torch.no_grad**",
   "id": "96663f07e66a736e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T08:53:41.587751Z",
     "start_time": "2025-05-17T08:53:41.582312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "# chain rule을 위해 계속 grad_fn 을 update 하니까 grad_fn 을 잠시 계산하고 싶지 않을 때 torch.no_grad 사용\n",
    "# 모델 테스트 시에는 불필요하게 메모리 쓸 필요 없기 때문!\n",
    "with torch.no_grad():\n",
    "    y = x**2\n",
    "    print(x.requires_grad)\n",
    "    print(y) # with 안에서 계산되는 애들은 grad_fn 이 붙지 않음\n",
    "print(x.requires_grad)\n",
    "#y.backward() # error\n",
    "y=x**2\n",
    "print(y)\n",
    "\n",
    "x = torch.tensor([1.,], requires_grad=True)\n",
    "x.requires_grad = False\n",
    "y = x**2\n",
    "print(x.requires_grad)\n",
    "print(y)\n",
    "#y.backward() # error"
   ],
   "id": "5926d4c870794e82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([1.])\n",
      "True\n",
      "tensor([1.], grad_fn=<PowBackward0>)\n",
      "False\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T08:54:04.875750Z",
     "start_time": "2025-05-17T08:54:02.093858Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install torchviz",
   "id": "cfe29b33660cf77c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchviz\r\n",
      "  Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\r\n",
      "Collecting graphviz\r\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.1/47.1 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: torch in /Users/seungheon-i/miniconda3/envs/upstage/lib/python3.8/site-packages (from torchviz) (2.4.1)\r\n",
      "Requirement already satisfied: sympy in /Users/seungheon-i/miniconda3/envs/upstage/lib/python3.8/site-packages (from torch->torchviz) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /Users/seungheon-i/miniconda3/envs/upstage/lib/python3.8/site-packages (from torch->torchviz) (3.1)\r\n",
      "Requirement already satisfied: fsspec in /Users/seungheon-i/miniconda3/envs/upstage/lib/python3.8/site-packages (from torch->torchviz) (2025.3.0)\r\n",
      "Requirement already satisfied: jinja2 in /Users/seungheon-i/miniconda3/envs/upstage/lib/python3.8/site-packages (from torch->torchviz) (3.1.6)\r\n",
      "Requirement already satisfied: filelock in /Users/seungheon-i/miniconda3/envs/upstage/lib/python3.8/site-packages (from torch->torchviz) (3.16.1)\r\n",
      "Collecting typing-extensions>=4.8.0\r\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/seungheon-i/miniconda3/envs/upstage/lib/python3.8/site-packages (from jinja2->torch->torchviz) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/seungheon-i/miniconda3/envs/upstage/lib/python3.8/site-packages (from sympy->torch->torchviz) (1.3.0)\r\n",
      "Installing collected packages: typing-extensions, graphviz, torchviz\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.5.0\r\n",
      "    Uninstalling typing_extensions-4.5.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.5.0\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-macos 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.13.2 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed graphviz-0.20.3 torchviz-0.0.3 typing-extensions-4.13.2\r\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T09:06:19.571146Z",
     "start_time": "2025-05-17T09:06:19.398586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "x = torch.tensor([1.,], requires_grad=True)\n",
    "make_dot(x**2+1)"
   ],
   "id": "c0254018aee88cd7",
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n -->\n<!-- Pages: 1 -->\n<svg width=\"108pt\" height=\"280pt\"\n viewBox=\"0.00 0.00 108.00 279.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 275.75)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-275.75 104,-275.75 104,4 -4,4\"/>\n<!-- 5355419744 -->\n<g id=\"node1\" class=\"node\">\n<title>5355419744</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"77,-32.75 23,-32.75 23,0 77,0 77,-32.75\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 5367926448 -->\n<g id=\"node2\" class=\"node\">\n<title>5367926448</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-89.5 6,-89.5 6,-68.75 94,-68.75 94,-89.5\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 5367926448&#45;&gt;5355419744 -->\n<g id=\"edge4\" class=\"edge\">\n<title>5367926448&#45;&gt;5355419744</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50,-68.36C50,-61.89 50,-53.05 50,-44.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-44.55 50,-34.55 46.5,-44.55 53.5,-44.55\"/>\n</g>\n<!-- 5367923184 -->\n<g id=\"node3\" class=\"node\">\n<title>5367923184</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-146.25 6,-146.25 6,-125.5 94,-125.5 94,-146.25\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 5367923184&#45;&gt;5367926448 -->\n<g id=\"edge1\" class=\"edge\">\n<title>5367923184&#45;&gt;5367926448</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50,-125.09C50,-118.47 50,-109.47 50,-101.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-101.34 50,-91.34 46.5,-101.34 53.5,-101.34\"/>\n</g>\n<!-- 5367925104 -->\n<g id=\"node4\" class=\"node\">\n<title>5367925104</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-203 0,-203 0,-182.25 100,-182.25 100,-203\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 5367925104&#45;&gt;5367923184 -->\n<g id=\"edge2\" class=\"edge\">\n<title>5367925104&#45;&gt;5367923184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50,-181.84C50,-175.22 50,-166.22 50,-158.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-158.09 50,-148.09 46.5,-158.09 53.5,-158.09\"/>\n</g>\n<!-- 5368662512 -->\n<g id=\"node5\" class=\"node\">\n<title>5368662512</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77,-271.75 23,-271.75 23,-239 77,-239 77,-271.75\"/>\n<text text-anchor=\"middle\" x=\"50\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 5368662512&#45;&gt;5367925104 -->\n<g id=\"edge3\" class=\"edge\">\n<title>5368662512&#45;&gt;5367925104</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50,-238.73C50,-231.35 50,-222.43 50,-214.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-214.66 50,-204.66 46.5,-214.66 53.5,-214.66\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x13ff40ee0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bf792dcab50adc5c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
